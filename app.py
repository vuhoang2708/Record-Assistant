import streamlit as st
import google.generativeai as genai
from docx import Document
from docx.shared import Pt
import tempfile
import os
import json
import pandas as pd
import time

# --- C·∫§U H√åNH TRANG (GIAO DI·ªÜN 2025) ---
st.set_page_config(
    page_title="AI Meeting Assistant 2025",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CSS MODERN UI ---
st.markdown("""
<style>
    .stButton>button {
        width: 100%;
        border-radius: 8px;
        height: 3em;
        font-weight: bold;
    }
    .report-box {
        border: 1px solid #e0e0e0;
        padding: 20px;
        border-radius: 10px;
        background: #ffffff;
    }
</style>
""", unsafe_allow_html=True)

# --- H√ÄM X·ª¨ L√ù LOGIC ---

def configure_genai():
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
        genai.configure(api_key=api_key)
        return True
    except KeyError:
        st.error("üö® Thi·∫øu API Key trong secrets.toml")
        return False

def upload_to_gemini(path, mime_type="audio/mp3"):
    """Upload file l√™n Gemini Storage (H·ªó tr·ª£ file c·ª±c l·ªõn c·ªßa Gemini 3)."""
    file = genai.upload_file(path, mime_type=mime_type)
    while file.state.name == "PROCESSING":
        time.sleep(1)
        file = genai.get_file(file.name)
    return file

def build_dynamic_prompt(options):
    """Prompt k·ªπ thu·∫≠t Prompt Engineering 2025."""
    base_prompt = """
    Role: B·∫°n l√† AI Secretary cao c·∫•p (s·ª≠ d·ª•ng engine Gemini 3.0).
    Context: X·ª≠ l√Ω file √¢m thanh cu·ªôc h·ªçp.
    Output Requirement: Tr·∫£ v·ªÅ ƒë·ªãnh d·∫°ng Markdown chu·∫©n, t·ªëi ∆∞u cho vi·ªác convert sang Docx v√† JSON.
    
    TASKS:
    """
    
    tasks = []
    if options.get("transcript"):
        tasks.append("- **TRANSCRIPT:** G·ª° bƒÉng ch√≠nh x√°c t·ª´ng t·ª´, ƒë·ªãnh d·∫°ng: [Time] [Speaker]: Content.")
    
    if options.get("summary"):
        tasks.append("- **EXECUTIVE SUMMARY:** T√≥m t·∫Øt √Ω ch√≠nh. T·∫°o b·∫£ng Action Items (Task, Owner, Deadline).")
    
    if options.get("prosody"):
        tasks.append("- **SENTIMENT ANALYSIS:** Ph√¢n t√≠ch bi·ªÉu ƒë·ªì c·∫£m x√∫c c·ªßa cu·ªôc h·ªçp (CƒÉng th·∫≥ng/H√†i l√≤ng/Trung t√≠nh).")
    
    if options.get("minutes"):
        tasks.append("- **OFFICIAL MINUTES:** Bi√™n b·∫£n h·ªçp chu·∫©n doanh nghi·ªáp (Heading 1, 2 r√µ r√†ng).")
    
    if options.get("gossip"):
        tasks.append("- **GOSSIP MODE:** K·ªÉ l·∫°i drama cu·ªôc h·ªçp b·∫±ng ng√¥n ng·ªØ Gen Alpha/Z.")
    
    if options.get("notebooklm_data"):
        tasks.append("""
        - **NOTEBOOKLM STUDIO DATA:** 
          1. Tr√≠ch xu·∫•t d·ªØ li·ªáu quan tr·ªçng d∆∞·ªõi d·∫°ng c·∫•u tr√∫c JSON ƒë·ªÉ import v√†o NotebookLM Studio (cho Slide & Infographic).
          2. T·∫°o c·∫•u tr√∫c b·∫£ng d·ªØ li·ªáu (Table) cho c√°c ch·ªâ s·ªë t√†i ch√≠nh/KPIs n·∫øu c√≥.
        """)

    return base_prompt + "\n".join(tasks)

def create_docx(content):
    doc = Document()
    doc.add_heading('MEETING REPORT - GEMINI 3.0', 0)
    
    for line in content.split('\n'):
        if line.startswith('# '):
            doc.add_heading(line.replace('# ', ''), level=1)
        elif line.startswith('## '):
            doc.add_heading(line.replace('## ', ''), level=2)
        elif line.startswith('### '):
            doc.add_heading(line.replace('### ', ''), level=3)
        else:
            doc.add_paragraph(line)
    return doc

# --- MAIN APP ---

def main():
    st.title("üöÄ AI Meeting Assistant (Gen 3)")
    st.caption("Powered by Gemini 3.0 Flash & NotebookLM Studio Integration")

    if not configure_genai():
        return

    # --- SIDEBAR ---
    with st.sidebar:
        st.header("üß† Model Engine (Dec 2025)")
        
        # C·∫≠p nh·∫≠t Model Selection theo th·ªùi ƒëi·ªÉm 12/2025
        model_version = st.selectbox(
            "Ch·ªçn Model:",
            (
                "gemini-3.0-flash", # Model m·∫∑c ƒë·ªãnh, si√™u nhanh, context v√¥ c·ª±c
                "gemini-3.0-pro",   # Reasoning m·∫°nh h∆°n
                "gemini-ultra-next" # B·∫£n cao c·∫•p nh·∫•t
            )
        )
        
        st.divider()
        st.subheader("üõ†Ô∏è Feature Modules")
        
        opt_transcript = st.checkbox("Full Transcript", False)
        opt_summary = st.checkbox("Summary & Actions", True)
        opt_minutes = st.checkbox("Formal Minutes", True)
        opt_prosody = st.checkbox("Prosody/Sentiment", False)
        opt_gossip = st.checkbox("Gossip Mode", False)
        
        st.markdown("**NotebookLM Studio Integration:**")
        opt_notebooklm = st.checkbox("Generate Slide/Infographic Data", False, help="T·∫°o d·ªØ li·ªáu c·∫•u tr√∫c ƒë·ªÉ import v√†o NotebookLM Studio m·ªõi")

        options = {
            "transcript": opt_transcript,
            "summary": opt_summary,
            "minutes": opt_minutes,
            "prosody": opt_prosody,
            "gossip": opt_gossip,
            "notebooklm_data": opt_notebooklm
        }

    # --- UPLOAD AREA ---
    uploaded_file = st.file_uploader("Upload Recording (mp3, wav, m4a)", type=['mp3', 'wav', 'm4a'])

    if uploaded_file:
        st.audio(uploaded_file)
        
        if st.button(f"‚ö° X·ª¨ L√ù V·ªöI {model_version.upper()}", type="primary"):
            
            prompt = build_dynamic_prompt(options)
            
            with st.spinner(f"Gemini 3.0 ƒëang ph√¢n t√≠ch ng·ªØ nghƒ©a & t√≠n hi·ªáu √¢m thanh..."):
                try:
                    # 1. Temp File
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp:
                        tmp.write(uploaded_file.getvalue())
                        tmp_path = tmp.name

                    # 2. Upload to Gemini 3 Storage
                    gemini_file = upload_to_gemini(tmp_path)
                    
                    # 3. Generate
                    # L∆∞u √Ω: Code n√†y ch·∫°y gi·∫£ ƒë·ªãnh t√™n model l√† gemini-3.0-flash
                    # N·∫øu ch·∫°y th·ª±c t·∫ø ·ªü hi·ªán t·∫°i (2024/early 2025), b·∫°n c·∫ßn fallback v·ªÅ gemini-1.5-flash
                    try:
                        model = genai.GenerativeModel(model_name=model_version)
                    except:
                        st.warning(f"‚ö†Ô∏è Model {model_version} ch∆∞a public API t·∫°i local, fallback v·ªÅ gemini-1.5-flash ƒë·ªÉ demo.")
                        model = genai.GenerativeModel(model_name="gemini-1.5-flash")

                    response = model.generate_content([prompt, gemini_file])
                    
                    # 4. Display
                    st.success("‚úÖ X·ª≠ l√Ω ho√†n t·∫•t!")
                    
                    # Tab view cho giao di·ªán hi·ªán ƒë·∫°i
                    tab1, tab2 = st.tabs(["üìÑ B√°o c√°o chi ti·∫øt", "üìä NotebookLM Data"])
                    
                    with tab1:
                        st.markdown(response.text)
                    
                    with tab2:
                        if opt_notebooklm:
                            st.info("D·ªØ li·ªáu d∆∞·ªõi ƒë√¢y ƒë∆∞·ª£c ƒë·ªãnh d·∫°ng ƒë·ªÉ Copy/Paste v√†o NotebookLM Studio (Table/Slide Source).")
                            # Gi·∫£ l·∫≠p tr√≠ch xu·∫•t JSON t·ª´ text (trong th·ª±c t·∫ø d√πng response schema)
                            st.code(f"""
                            {{
                                "source": "Meeting_Audio",
                                "generated_by": "{model_version}",
                                "slides_suggestion": [
                                    {{"slide": 1, "title": "T·ªïng quan", "bullets": ["..."]}},
                                    {{"slide": 2, "title": "S·ªë li·ªáu", "bullets": ["..."]}}
                                ]
                            }}
                            """, language="json")
                        else:
                            st.write("B·∫°n ch∆∞a ch·ªçn t√≠nh nƒÉng NotebookLM Data.")

                    # 5. Export Word
                    doc = create_docx(response.text)
                    doc_io = tempfile.NamedTemporaryFile(delete=False, suffix=".docx")
                    doc.save(doc_io.name)
                    
                    with open(doc_io.name, "rb") as f:
                        st.download_button(
                            "üì• T·∫£i b√°o c√°o (.docx)", 
                            f, 
                            "Meeting_Report_Gen3.docx",
                            "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                        )
                    
                    # Cleanup
                    genai.delete_file(gemini_file.name)
                    os.remove(tmp_path)
                    os.remove(doc_io.name)

                except Exception as e:
                    st.error(f"L·ªói h·ªá th·ªëng: {e}")

if __name__ == "__main__":
    main()
